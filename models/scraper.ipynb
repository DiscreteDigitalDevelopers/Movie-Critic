{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e018a0-0553-454e-a9fd-b14f41f330e8",
   "metadata": {},
   "source": [
    "# IMDB Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06aa88-56b3-4d3f-bcdf-bfdb4ed59229",
   "metadata": {},
   "source": [
    "Script to scrape reviews and ratings of a movie / tvshow from IMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf70728-85d2-4c0c-9b95-6804a9dcfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa104bb6-0639-4dc0-8ee1-59154e0ac435",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee9e879-d729-4cd6-9aaf-36c95a512b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'data.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8188ec-7e1a-4d1b-8645-90e810f2ee83",
   "metadata": {},
   "source": [
    "Read tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "725b0671-1231-4011-b889-9edf9f1879c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f5bc0a-802e-47d7-b413-da34bfe67f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>5.8</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>5.6</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  averageRating  numVotes\n",
       "0  tt0000001            5.7      1924\n",
       "1  tt0000002            5.8       260\n",
       "2  tt0000003            6.5      1736\n",
       "3  tt0000004            5.6       175\n",
       "4  tt0000005            6.2      2551"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7290bbd6-6108-4f2d-9beb-ab2f7f6ddfca",
   "metadata": {},
   "source": [
    "Row count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f85e064-72cc-4558-ac89-9a530217d4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252779"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d28906-f226-43f1-8839-242dea651416",
   "metadata": {},
   "source": [
    "Randomly sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c902c774-e8d6-4523-90b3-ada76b7e2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idxs = np.random.permutation(len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9c356-2c23-46ff-a1e3-783cbe755128",
   "metadata": {},
   "source": [
    "Exclude previously mined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81b6a870-3c8b-47c7-a921-07dfd8259903",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m28\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/ratings_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 5\u001b[0m         prev_data \u001b[38;5;241m=\u001b[39m \u001b[43mprev_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# extract existing keys\u001b[39;00m\n\u001b[0;32m      7\u001b[0m mined_tids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(prev_data\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "# load all previously trained data\n",
    "prev_data = {}\n",
    "for i in range(28):\n",
    "    with open(f'./data/ratings_{i}.pkl', 'rb') as f:\n",
    "        prev_data = prev_data | pickle.load(f)\n",
    "# extract existing keys\n",
    "mined_tids = set(prev_data.keys())\n",
    "print(len(mined_tids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fbc03-6325-4ac5-972e-f8f05e5deb52",
   "metadata": {},
   "source": [
    "## Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec73a0c-7db9-40f4-b649-c5f833ca25e1",
   "metadata": {},
   "source": [
    "Mine data from the web and save to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab26bd9-0add-4282-a22d-6b61e72bb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 20000\n",
    "SAVE_INTERVAL = 1000\n",
    "REVIEWS_PER_MOVIE = 5\n",
    "SAVE_LOCATION = './data/'\n",
    "START_ID = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045260de-da52-4496-8fc0-c791d4e6755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "count = 0\n",
    "save_counter = START_ID\n",
    "with tqdm(total=SAMPLE_SIZE) as pbar:\n",
    "    for idx in sample_idxs:\n",
    "        # check if exit loop\n",
    "        if count >= SAMPLE_SIZE:\n",
    "            break\n",
    "        # get metadata\n",
    "        metadata = df.iloc[idx]\n",
    "        tid, rating = metadata[0], metadata[1]\n",
    "        # exclude already mined data\n",
    "        if tid in mined_tids:\n",
    "            continue\n",
    "        # scrape reviews\n",
    "        raw = None\n",
    "        try:\n",
    "            raw = requests.get(f'https://www.imdb.com/title/{tid}/reviews?ref_=tt_urv')\n",
    "        except:\n",
    "            print(f'Error while mining {tid} ...')\n",
    "            continue\n",
    "        soup = BeautifulSoup(raw.text, 'html.parser')\n",
    "        r_text = []\n",
    "        for i, r_div in enumerate(soup.findAll('div', {'class': ['content']})):\n",
    "            review = r_div.find(class_ = 'text')\n",
    "            if i >= REVIEWS_PER_MOVIE:\n",
    "                break\n",
    "            r_text.append(review.text)\n",
    "        if len(r_text) == 0:\n",
    "            # no review found, continue searching\n",
    "            continue\n",
    "        # store data\n",
    "        data[tid] = (rating, ' '.join(r_text))\n",
    "        count += 1\n",
    "        pbar.update(1)\n",
    "        # save data if interval\n",
    "        if count % SAVE_INTERVAL == 0:\n",
    "            # dump data\n",
    "            print('saving checkpoint...')\n",
    "            with open(f'{SAVE_LOCATION}ratings_{save_counter}.pkl', 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "            save_counter += 1\n",
    "            # clear data\n",
    "            data.clear()\n",
    "# save data\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85febab8-1933-429e-989a-8e998e79f998",
   "metadata": {},
   "source": [
    "Train/Dev/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b5c2f-3cfd-4764-bca8-a8c66bb05343",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = [24,2,2]\n",
    "FILE_COUNT = 28\n",
    "\n",
    "ratio = np.cumsum(np.array(ratio))\n",
    "names = ['train', 'dev', 'test']\n",
    "ratings = {}\n",
    "mode = 0\n",
    "for i in range(FILE_COUNT):\n",
    "    with open(f'{SAVE_LOCATION}ratings_{i}.pkl', 'rb') as handle:\n",
    "        temp = pickle.load(handle)\n",
    "        # merge\n",
    "        ratings = ratings | temp\n",
    "    # dump file\n",
    "    if i == ratio[mode] - 1:\n",
    "        with open(f'{SAVE_LOCATION}processed/data_{names[mode]}.pkl', 'wb') as f:\n",
    "            pickle.dump(ratings, f)\n",
    "        mode += 1\n",
    "        ratings.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e113adf-4e40-44e5-b740-0df1a68b88a1",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c04af-958e-431f-ad3e-5d3cddca2ceb",
   "metadata": {},
   "source": [
    "Load pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e56ae2-cc50-419f-8d3c-705ee1fbbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = None\n",
    "dev_data = None\n",
    "test_data = None\n",
    "with open(f'{SAVE_LOCATION}processed/data_train.pkl', 'rb') as handle:\n",
    "    train_data = pickle.load(handle)\n",
    "with open(f'{SAVE_LOCATION}processed/data_dev.pkl', 'rb') as handle:\n",
    "    dev_data = pickle.load(handle)\n",
    "with open(f'{SAVE_LOCATION}processed/data_test.pkl', 'rb') as handle:\n",
    "    test_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd4d799-42d2-4903-a1f5-4b9fcbe5b756",
   "metadata": {},
   "source": [
    "Size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e1c629-fcf5-4840-a842-960e48f7a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset Size: train = {len(train_data)}, dev = {len(dev_data)}, test = {len(test_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3b6b2a-4e1d-40e8-8a36-fd3372d100bd",
   "metadata": {},
   "source": [
    "Ratings distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82cff5f-5b2f-4ef8-a930-1c5d3b8c6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "for k, v in train_data.items():\n",
    "    train_scores.append(v[0])\n",
    "dev_scores = []\n",
    "for k, v in dev_data.items():\n",
    "    dev_scores.append(v[0])\n",
    "test_scores = []\n",
    "for k, v in test_data.items():\n",
    "    test_scores.append(v[0])\n",
    "dist = [np.array(train_scores), np.array(dev_scores), np.array(test_scores)]\n",
    "plt.hist(dist, density = True, label=['Train', 'Dev', 'Test'])\n",
    "plt.title('Distribution of Ratings for each Dataset')\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442c48c-3af8-4b2c-85cf-8e36676c10f9",
   "metadata": {},
   "source": [
    "# Twitter Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c99d1-680b-42f7-ba78-d8121d7d6e93",
   "metadata": {},
   "source": [
    "Script to scrape twitter posts with a specific movie hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1904e4-526d-4ee2-969e-37976f8d5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_LOCATION = './twitter/'\n",
    "RESULTS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ddec02-e7d2-428d-a739-978bb6724b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = [\n",
    "    (7.3, '#blackpanther2'),\n",
    "    (8.4, '#TopGun'),\n",
    "    (6.9, '#NopeMovie'),\n",
    "    (6.3, '#ThorLoveAndThunder')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e52a89-f61d-4925-aaf1-c3de348d19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = []\n",
    "for score, hashtag in hashtags:\n",
    "    bearer_token = 'TOKEN'\n",
    "    def bearer_oauth(r):\n",
    "        r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "        r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "        return r\n",
    "    params = {'query': f'{hashtag} lang:en', 'max_results': RESULTS}\n",
    "    url = 'https://api.twitter.com/2/tweets/search/recent'\n",
    "    res = requests.get(url, auth=bearer_oauth, params=params).json()\n",
    "    data = [r['text'] for r in res['data']]\n",
    "    twitter_data.append((hashtag, score, data))\n",
    "with open(f'{SAVE_LOCATION}/data.pkl', 'wb') as f:\n",
    "    pickle.dump(twitter_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
